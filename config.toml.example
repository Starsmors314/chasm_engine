name = "Hero"
world = "worlds/generic-world-name"

# context_length is the context window of the model.
context_length = 2000
max_tokens = 250

loglevel = "info"

# params passed to the model, defined in their own section below
model = "local"

[storage]
# this is not used yet
chunk-size-tokens = 380
sources = 6

[models.OpenAI]
chat_model = "gpt-3.5-turbo"
completion_model = "text-davinci-edit-001"
api_base = "https://api.openai.com/v1"
api_key = "sk-your-super-secret-key"

[models.local]
# Oobabooga's text-generation-webui works well using the "openai" extension
# and setting the base url appropriately. Exllama is fast.
# I've been using Guanaco and Wizard-Vicuna-Uncensored, both 30B 4bit, with good results.
# I've tried Nous-Hermes 13B and it seems to be OK
api_base = "http://localhost:5001"
api_key = "N/A"
stop = ["</s>", "Assistant:"]
# truncation_length can be set in the gui, I think
